###############################################################################
# Copyright (c) 2022-25, Lawrence Livermore National Security, LLC and RADIUSS
# project contributors. See the COPYRIGHT file for details.
#
# SPDX-License-Identifier: (MIT)
###############################################################################

# The template job to test whether a machine is up.
# Expects CI_MACHINE defined to machine name.
.machine-check:
  stage: prerequisites
  tags: [shell, oslic]
  variables:
    GIT_STRATEGY: none
  script:
    - |
      # Check if required variables are set for machine checking
      if [ -z "$CI_MACHINE" ]; then
        echo -e "\e[31mError: CI_MACHINE variable not set\e[0m"
        exit 1
      fi

      # Check if lorenz status file exists
      LORENZ_STATUS_FILE="/usr/global/tools/lorenz/data/loginnodeStatus"
      if [ ! -f "$LORENZ_STATUS_FILE" ]; then
        echo -e "\e[31mError: Lorenz status file not found: $LORENZ_STATUS_FILE\e[0m"
        exit 1
      fi

      echo "Checking availability of machine: ${CI_MACHINE}"

      # Query machine status with error handling
      NODES_UP=$(jq -r ".[\"${CI_MACHINE}\"].total_nodes_up // \"null\"" "$LORENZ_STATUS_FILE" 2>/dev/null)
      JQ_EXIT_CODE=$?

      if [ $JQ_EXIT_CODE -ne 0 ]; then
        echo -e "\e[31mError: Failed to parse lorenz status file\e[0m"
        echo "File content sample:"
        head -n 5 "$LORENZ_STATUS_FILE" 2>/dev/null || echo "Cannot read file"
        exit 1
      fi

      if [ "$NODES_UP" = "null" ]; then
        echo -e "\e[31mError: Machine ${CI_MACHINE} not found in status file\e[0m"
        echo "Available machines in status file:"
        jq -r 'keys[]' "$LORENZ_STATUS_FILE" 2>/dev/null | head -10 || echo "Cannot list machines"
        exit 1
      fi

      # Check if machine is available - THIS is the only case we report to GitHub
      if [ "$NODES_UP" -eq 0 ]; then
        echo -e "\e[31mMachine ${CI_MACHINE} is down (${NODES_UP} nodes up)\e[0m"

        # Only report machine unavailability to GitHub
        if [ -n "$GITHUB_TOKEN" ] && [ -n "$GITHUB_PROJECT_ORG" ] && [ -n "$GITHUB_PROJECT_NAME" ]; then
          STATUS_RESPONSE=$(mktemp)
          STATUS_HTTP_CODE=$(curl --retry 3 --retry-delay 5 --max-time 30 \
              --url "https://api.github.com/repos/${GITHUB_PROJECT_ORG}/${GITHUB_PROJECT_NAME}/statuses/${CI_COMMIT_SHA}" \
              --header 'Content-Type: application/json' \
              --header "authorization: Bearer ${GITHUB_TOKEN}" \
              --data "{ \"state\": \"failure\", \"target_url\": \"${CI_PIPELINE_URL}\", \"description\": \"GitLab: ${CI_MACHINE} down (0 nodes)\", \"context\": \"ci/gitlab/${CI_MACHINE}\" }" \
              --output "$STATUS_RESPONSE" \
              --write-out "%{http_code}" \
              --silent \
              --show-error)

          echo "GitHub Status API response code: $STATUS_HTTP_CODE"

          if [ "$STATUS_HTTP_CODE" -eq 201 ]; then
            echo "Successfully reported machine down status to GitHub"
          else
            echo "Warning: Failed to report status to GitHub. HTTP status: $STATUS_HTTP_CODE"
            echo "Response body:"
            cat "$STATUS_RESPONSE"
          fi

          rm -f "$STATUS_RESPONSE"
        else
          echo "Warning: GitHub reporting variables not set, skipping GitHub status update"
        fi

        exit 1
      else
        echo -e "\e[32m${CI_MACHINE} is available (${NODES_UP} nodes up)\e[0m"
      fi

## [Shared jobs scenario]
## The job list can be imported from the .gitlab/jobs/<machine>.yml file, which
## is the default behavior of RADIUSS Shared CI. Or the list can be generated,
## allowing more complex setups, like sharing a list of jobs like we do with
## RADIUSS Spack Configs. Below is an example # job that concatenates jobs from
## two sources.
## (See Umpire CI setup for an example).
#
## One job to generate the job list for all the subpipelines
#generate-job-lists:
#  stage: prerequisites
#  tags: [shell, oslic]
#  variables:
#    LOCAL_JOBS_PATH: ".gitlab/jobs"
#    REMOTE_JOBS_PATH: "<remote/jobs/path>"
#  script:
#    - cat ${LOCAL_JOBS_PATH}/dane.yml ${REMOTE_JOBS_PATH}/dane.yml > dane-jobs.yml
#    - cat ${LOCAL_JOBS_PATH}/lassen.yml ${REMOTE_JOBS_PATH}/lassen.yml > lassen-jobs.yml
#    - cat ${LOCAL_JOBS_PATH}/corona.yml ${REMOTE_JOBS_PATH}/corona.yml > corona-jobs.yml
#    - cat ${LOCAL_JOBS_PATH}/tioga.yml ${REMOTE_JOBS_PATH}/tioga.yml > tioga-jobs.yml
#    - cat ${LOCAL_JOBS_PATH}/tuolumne.yml ${REMOTE_JOBS_PATH}/tuolumne.yml > tuolumne-jobs.yml
#  artifacts:
#    paths:
#      - dane-jobs.yml
#      - lassen-jobs.yml
#      - corona-jobs.yml
#      - tuolumne-jobs.yml

###
# Trigger a build-and-test pipeline for a machine.
# Comment the jobs for machines you donâ€™t need.
###

# DANE
dane-up-check:
  variables:
    CI_MACHINE: "dane"
  extends: [.machine-check]
  rules:
    # Runs except if we explicitly deactivate dane by variable.
    - if: '$ON_DANE == "OFF"'
      when: never
    - when: on_success

dane-build-and-test:
  variables:
    CI_MACHINE: "dane"
  needs: [dane-up-check]
  ## [Shared jobs scenario]
  ## (See Umpire CI setup for an example).
  #needs: [dane-up-check, generate-job-lists]
  extends: [.build-and-test]
  rules:
    # Runs except if we explicitly deactivate dane by variable.
    - if: '$ON_DANE == "OFF"'
      when: never
    - when: on_success

# MATRIX
matrix-up-check:
  variables:
    CI_MACHINE: "matrix"
  extends: [.machine-check]
  rules:
    # Runs except if we explicitly deactivate matrix by variable.
    - if: '$ON_MATRIX == "OFF"'
      when: never
    - when: on_success

matrix-build-and-test:
  variables:
    CI_MACHINE: "matrix"
  needs: [matrix-up-check]
  ## [Shared jobs scenario]
  ## (See Umpire CI setup for an example).
  #needs: [matrix-up-check, generate-job-lists]
  extends: [.build-and-test]
  rules:
    # Runs except if we explicitly deactivate matrix by variable.
    - if: '$ON_MATRIX == "OFF"'
      when: never
    - when: on_success

# CORONA
corona-up-check:
  variables:
    CI_MACHINE: "corona"
  extends: [.machine-check]
  rules:
    - if: '$ON_CORONA == "OFF"'
      when: never
    - when: on_success

corona-build-and-test:
  variables:
    CI_MACHINE: "corona"
  needs: [corona-up-check]
  ## [Shared jobs scenario]
  ## (See Umpire CI setup for an example).
  #needs: [corona-up-check, generate-job-lists]
  extends: [.build-and-test]
  rules:
    - if: '$ON_CORONA == "OFF"'
      when: never
    - when: on_success

# TIOGA
tioga-up-check:
  variables:
    CI_MACHINE: "tioga"
  extends: [.machine-check]
  rules:
    - if: '$ON_TIOGA == "OFF"'
      when: never
    - when: on_success

tioga-build-and-test:
  variables:
    CI_MACHINE: "tioga"
  needs: [tioga-up-check]
  ## [Shared jobs scenario]
  ## (See Umpire CI setup for an example).
  #needs: [tioga-up-check, generate-job-lists]
  extends: [.build-and-test]
  rules:
    - if: '$ON_TIOGA == "OFF"'
      when: never
    - when: on_success

# TUOLUMNE
tuolumne-up-check:
  variables:
    CI_MACHINE: "tuolumne"
  extends: [.machine-check]
  rules:
    - if: '$ON_TUOLUMNE == "OFF"'
      when: never
    - when: on_success

tuolumne-build-and-test:
  variables:
    CI_MACHINE: "tuolumne"
  needs: [tuolumne-up-check]
  ## [Shared jobs scenario]
  ## (See Umpire CI setup for an example).
  #needs: [tuolumne-up-check, generate-job-lists]
  extends: [.build-and-test]
  rules:
    - if: '$ON_TUOLUMNE == "OFF"'
      when: never
    - when: on_success

# LASSEN
lassen-up-check:
  variables:
    CI_MACHINE: "lassen"
  extends: [.machine-check]
  rules:
    - if: '$ON_LASSEN == "OFF"'
      when: never
    - when: on_success

lassen-build-and-test:
  variables:
    CI_MACHINE: "lassen"
  needs: [lassen-up-check]
  ## [Shared jobs scenario]
  ## (See Umpire CI setup for an example).
  #needs: [lassen-up-check, generate-job-lists]
  extends: [.build-and-test]
  rules:
    - if: '$ON_LASSEN == "OFF"'
      when: never
    - when: on_success
